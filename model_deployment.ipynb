{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e0472b8",
   "metadata": {},
   "source": [
    "# Model Deployment for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7823fa",
   "metadata": {},
   "source": [
    "## 1. Introduction to Model Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9314c406",
   "metadata": {},
   "source": [
    "\n",
    "### What is Model Deployment?\n",
    "\n",
    "Model deployment is the process of making a machine learning model available for use in a production environment. Once a model has been trained, it needs to be deployed to allow end-users or other systems to interact with it and get predictions.\n",
    "\n",
    "The key stages in model deployment include:\n",
    "- **Saving the Model**: Storing the trained model in a format that can be loaded later.\n",
    "- **Serving the Model**: Setting up an API or interface to serve the model to clients or users.\n",
    "- **Monitoring the Model**: Ensuring that the model continues to perform well over time by monitoring its predictions and retraining if necessary.\n",
    "\n",
    "## 2. Saving and Loading Models\n",
    "\n",
    "The first step in deploying a model is to save it after training. This ensures that the model can be reloaded without having to retrain it.\n",
    "\n",
    "### Example: Saving and Loading a Model Using `joblib`\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc3e42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "# Load the Iris dataset\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a RandomForest model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model to a file\n",
    "joblib.dump(model, 'random_forest_model.pkl')\n",
    "\n",
    "# Load the model from the file\n",
    "loaded_model = joblib.load('random_forest_model.pkl')\n",
    "\n",
    "# Use the loaded model for prediction\n",
    "loaded_model.predict(X_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3a7fa8",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Model Serving with Flask\n",
    "\n",
    "To serve the model, we need to create an API that can accept requests, pass the input to the model, and return predictions. Flask is a lightweight web framework that can be used to create APIs.\n",
    "\n",
    "### Example: Creating a Flask API for Model Deployment\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d5a8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example: A basic Flask app for serving a machine learning model\n",
    "# from flask import Flask, request, jsonify\n",
    "# import joblib\n",
    "# import numpy as np\n",
    "# \n",
    "# app = Flask(__name__)\n",
    "# \n",
    "# # Load the saved model\n",
    "# model = joblib.load('random_forest_model.pkl')\n",
    "# \n",
    "# @app.route('/predict', methods=['POST'])\n",
    "# def predict():\n",
    "#     # Get the input data from the request\n",
    "#     data = request.json['data']\n",
    "#     data = np.array(data)\n",
    "#     \n",
    "#     # Make predictions using the model\n",
    "#     prediction = model.predict(data)\n",
    "#     \n",
    "#     # Return the predictions as a JSON response\n",
    "#     return jsonify({'prediction': prediction.tolist()})\n",
    "# \n",
    "# if __name__ == '__main__':\n",
    "#     app.run(debug=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422fa599",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Docker for Model Deployment\n",
    "\n",
    "Docker is a popular platform for containerizing applications, making it easier to deploy machine learning models across different environments. By packaging the model, code, and dependencies in a Docker container, we can ensure consistent behavior regardless of the underlying system.\n",
    "\n",
    "### Example: Dockerfile for Deploying the Flask API\n",
    "\n",
    "```\n",
    "# Use a base Python image\n",
    "FROM python:3.8-slim\n",
    "\n",
    "# Set the working directory\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy the requirements file and install dependencies\n",
    "COPY requirements.txt .\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "# Copy the rest of the application\n",
    "COPY . .\n",
    "\n",
    "# Expose the port the app runs on\n",
    "EXPOSE 5000\n",
    "\n",
    "# Run the Flask app\n",
    "CMD [\"python\", \"app.py\"]\n",
    "```\n",
    "\n",
    "## 5. Monitoring and Retraining\n",
    "\n",
    "Once deployed, it is important to monitor the performance of the model in production. This can be done by logging predictions, measuring accuracy over time, and tracking data drift. If the model's performance deteriorates, retraining the model with new data may be necessary.\n",
    "\n",
    "## Applications in Machine Learning\n",
    "\n",
    "- **Web Applications**: Deploy machine learning models as APIs for web applications.\n",
    "- **Mobile Applications**: Serve models via an API to mobile apps for tasks like image recognition or recommendation systems.\n",
    "- **Monitoring and Retraining**: Continuously improve models by monitoring their performance and updating them with new data.\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
