{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ec72635",
   "metadata": {},
   "source": [
    "# Model Evaluation and Validation for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61ab766",
   "metadata": {},
   "source": [
    "## 1. Model Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0afb8b5",
   "metadata": {},
   "source": [
    "\n",
    "### What is Model Evaluation?\n",
    "\n",
    "Model evaluation is the process of assessing how well a machine learning model performs on unseen data. Proper evaluation is crucial to avoid overfitting and ensure that the model generalizes well.\n",
    "\n",
    "### Common Evaluation Metrics:\n",
    "\n",
    "1. **Accuracy**: The proportion of correctly classified samples.\n",
    "   \\[\n",
    "   \text{Accuracy} = \f",
    "rac{\text{Correct Predictions}}{\text{Total Predictions}}\n",
    "   \\]\n",
    "\n",
    "2. **Precision**: The proportion of true positives out of all predicted positives.\n",
    "   \\[\n",
    "   \text{Precision} = \f",
    "rac{\text{True Positives}}{\text{True Positives} + \text{False Positives}}\n",
    "   \\]\n",
    "\n",
    "3. **Recall**: The proportion of true positives out of all actual positives.\n",
    "   \\[\n",
    "   \text{Recall} = \f",
    "rac{\text{True Positives}}{\text{True Positives} + \text{False Negatives}}\n",
    "   \\]\n",
    "\n",
    "4. **F1-Score**: The harmonic mean of precision and recall.\n",
    "   \\[\n",
    "   \text{F1-Score} = 2 \\cdot \f",
    "rac{\text{Precision} \\cdot \text{Recall}}{\text{Precision} + \text{Recall}}\n",
    "   \\]\n",
    "\n",
    "5. **ROC-AUC**: The area under the Receiver Operating Characteristic curve, which plots the true positive rate against the false positive rate.\n",
    "\n",
    "### Example: Calculating Accuracy, Precision, Recall, and F1-Score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37dddac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Example data\n",
    "y_true = [1, 0, 1, 1, 0, 1, 0]\n",
    "y_pred = [1, 0, 1, 0, 0, 1, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "accuracy, precision, recall, f1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cb75de",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Cross-Validation\n",
    "\n",
    "Cross-validation is a technique used to assess the generalization performance of a model. It splits the data into several folds and trains the model multiple times on different subsets of the data.\n",
    "\n",
    "### Types of Cross-Validation:\n",
    "1. **k-Fold Cross-Validation**: The data is divided into \\( k \\) subsets, and the model is trained \\( k \\) times, each time using one subset as the test set and the remaining \\( k-1 \\) subsets as the training set.\n",
    "2. **Leave-One-Out Cross-Validation (LOO-CV)**: A special case of k-fold where \\( k \\) equals the number of samples, leaving one sample out as the test set.\n",
    "\n",
    "### Example: Performing k-Fold Cross-Validation\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fafeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Example: Performing 5-fold cross-validation\n",
    "X = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7], [7, 8]])\n",
    "y = np.array([1, 0, 1, 1, 0, 1, 0])\n",
    "\n",
    "model = LogisticRegression()\n",
    "cv_scores = cross_val_score(model, X, y, cv=5)\n",
    "\n",
    "cv_scores\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2ad2ce",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Overfitting and Underfitting\n",
    "\n",
    "- **Overfitting** occurs when the model is too complex and fits the noise in the training data, resulting in poor generalization to new data.\n",
    "- **Underfitting** occurs when the model is too simple and fails to capture the underlying patterns in the data.\n",
    "\n",
    "To avoid overfitting, techniques like **cross-validation**, **regularization**, and **early stopping** are used.\n",
    "\n",
    "### Regularization Techniques\n",
    "\n",
    "Regularization adds a penalty to the model complexity to prevent overfitting. Common techniques include:\n",
    "1. **L1 Regularization (Lasso)**: Adds a penalty proportional to the absolute value of the coefficients.\n",
    "2. **L2 Regularization (Ridge)**: Adds a penalty proportional to the square of the coefficients.\n",
    "\n",
    "### Example: Applying L2 Regularization\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8753c3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Example: Applying L2 regularization (Ridge regression)\n",
    "model_ridge = Ridge(alpha=1.0)\n",
    "model_ridge.fit(X, y)\n",
    "\n",
    "model_ridge.coef_\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2f4aa6",
   "metadata": {},
   "source": [
    "\n",
    "### Applications in Machine Learning\n",
    "\n",
    "- **Evaluation metrics** help quantify model performance in classification and regression tasks.\n",
    "- **Cross-validation** ensures the model generalizes well to new data.\n",
    "- **Regularization** techniques prevent overfitting and improve model robustness.\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
