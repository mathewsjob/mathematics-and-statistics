{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1fa7f3a",
   "metadata": {},
   "source": [
    "# Ensemble Methods for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eeb5545",
   "metadata": {},
   "source": [
    "## 1. What are Ensemble Methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f9aa7e",
   "metadata": {},
   "source": [
    "\n",
    "### Ensemble Methods\n",
    "\n",
    "Ensemble methods are techniques that combine the predictions of multiple models to improve performance and reduce overfitting. The idea is that by combining different models, the overall model can make better predictions than any individual model.\n",
    "\n",
    "### Types of Ensemble Methods\n",
    "\n",
    "1. **Bagging (Bootstrap Aggregating)**: Multiple models (e.g., decision trees) are trained on different random subsets of the data, and their predictions are averaged. Bagging reduces variance and is effective for high-variance models.\n",
    "   - **Example**: Random Forest.\n",
    "\n",
    "2. **Boosting**: Models are trained sequentially, and each new model focuses on the mistakes made by the previous ones. Boosting reduces bias and is effective for high-bias models.\n",
    "   - **Example**: Gradient Boosting, AdaBoost, XGBoost.\n",
    "\n",
    "3. **Stacking**: Models are combined by training a meta-model on the predictions of several base models.\n",
    "\n",
    "### Example: Bagging with Random Forest\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befaa06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Example: Using Random Forest (Bagging)\n",
    "rf_model = RandomForestClassifier(n_estimators=100)\n",
    "rf_model.fit(X, y)\n",
    "\n",
    "# Predicting with Random Forest\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "y_pred_rf\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56cc5ec",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Boosting\n",
    "\n",
    "Boosting is an ensemble technique where models are trained sequentially, and each subsequent model attempts to correct the errors of the previous models.\n",
    "\n",
    "### Example: Boosting with AdaBoost\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b3370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# Example: Using AdaBoost (Boosting)\n",
    "ada_model = AdaBoostClassifier(n_estimators=50)\n",
    "ada_model.fit(X, y)\n",
    "\n",
    "# Predicting with AdaBoost\n",
    "y_pred_ada = ada_model.predict(X_test)\n",
    "y_pred_ada\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363542ff",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Stacking\n",
    "\n",
    "Stacking combines the predictions of multiple models by training a meta-model on their outputs. This meta-model attempts to improve the overall predictions by learning from the predictions of the base models.\n",
    "\n",
    "### Example: Stacking with Multiple Models\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92830d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Example: Using Stacking\n",
    "estimators = [('rf', RandomForestClassifier(n_estimators=50)), \n",
    "              ('ada', AdaBoostClassifier(n_estimators=50))]\n",
    "\n",
    "stack_model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "stack_model.fit(X, y)\n",
    "\n",
    "# Predicting with Stacking\n",
    "y_pred_stack = stack_model.predict(X_test)\n",
    "y_pred_stack\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04508b00",
   "metadata": {},
   "source": [
    "\n",
    "## Applications in Machine Learning\n",
    "\n",
    "- **Bagging** reduces variance by averaging predictions from multiple models.\n",
    "- **Boosting** reduces bias by focusing on errors made by previous models.\n",
    "- **Stacking** combines the strengths of multiple models to improve overall performance.\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
