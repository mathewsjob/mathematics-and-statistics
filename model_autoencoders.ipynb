{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed69933c",
   "metadata": {},
   "source": [
    "# Autoencoders for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a174be",
   "metadata": {},
   "source": [
    "## 1. Introduction to Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6525dc",
   "metadata": {},
   "source": [
    "\n",
    "### What are Autoencoders?\n",
    "\n",
    "Autoencoders are a type of neural network used for unsupervised learning. They are trained to reconstruct their input data by learning a compressed representation (encoding) of the input. Autoencoders are widely used for tasks such as dimensionality reduction, anomaly detection, and denoising.\n",
    "\n",
    "An autoencoder consists of two main parts:\n",
    "1. **Encoder**: Maps the input data into a lower-dimensional space (latent space).\n",
    "2. **Decoder**: Reconstructs the input data from the latent representation.\n",
    "\n",
    "### Example: Simple Autoencoder Using Keras\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02f3837",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Example: Creating a simple autoencoder\n",
    "input_dim = 784  # For a 28x28 image (e.g., MNIST)\n",
    "encoding_dim = 32  # Compressed representation\n",
    "\n",
    "# Building the encoder\n",
    "autoencoder = Sequential([\n",
    "    Dense(encoding_dim, activation='relu', input_shape=(input_dim,)),\n",
    "    Dense(input_dim, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compiling the autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Summary of the model\n",
    "autoencoder.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c19e87c",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Training Autoencoders\n",
    "\n",
    "Autoencoders are trained by minimizing the reconstruction error, which is the difference between the original input and the reconstructed output. The goal is for the network to learn meaningful features in the data through the compressed representation.\n",
    "\n",
    "### Example: Training the Autoencoder\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5a5f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assume X_train is the input data (e.g., flattened 28x28 images)\n",
    "# Training the autoencoder\n",
    "# history = autoencoder.fit(X_train, X_train, epochs=50, batch_size=256, validation_split=0.2)\n",
    "# You would replace X_train with actual data in practice\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37ee354",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Applications of Autoencoders\n",
    "\n",
    "1. **Dimensionality Reduction**: Autoencoders can be used as an alternative to PCA for reducing the dimensionality of data.\n",
    "2. **Anomaly Detection**: By training an autoencoder on normal data, anomalies (which have higher reconstruction error) can be detected.\n",
    "3. **Denoising**: Autoencoders can remove noise from data by learning a clean representation of the data.\n",
    "4. **Image Compression**: Autoencoders can compress images into lower-dimensional representations and then reconstruct the original images.\n",
    "\n",
    "### Example: Denoising Autoencoder\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5abe697",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.layers import GaussianNoise\n",
    "\n",
    "# Example: Creating a denoising autoencoder\n",
    "denoising_autoencoder = Sequential([\n",
    "    Dense(encoding_dim, activation='relu', input_shape=(input_dim,)),\n",
    "    Dense(input_dim, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Adding noise to the input data\n",
    "denoising_autoencoder.add(GaussianNoise(0.2))  # Adding noise to the autoencoder\n",
    "\n",
    "denoising_autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "denoising_autoencoder.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a66afd4",
   "metadata": {},
   "source": [
    "\n",
    "## Applications in Machine Learning\n",
    "\n",
    "- **Dimensionality Reduction**: Autoencoders can be used for feature extraction in unsupervised learning.\n",
    "- **Anomaly Detection**: Autoencoders are effective in detecting outliers or rare events by reconstructing normal data.\n",
    "- **Denoising**: Autoencoders can remove noise from images or other data by learning a cleaner representation.\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
