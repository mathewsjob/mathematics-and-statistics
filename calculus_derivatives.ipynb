{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf8e72d2",
   "metadata": {},
   "source": [
    "# Calculus for Machine Learning: Derivatives and Differentiation Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbe0620",
   "metadata": {},
   "source": [
    "## 1. Derivatives and Differentiation Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e85b5b0",
   "metadata": {},
   "source": [
    "\n",
    "### What is a Derivative?\n",
    "\n",
    "In calculus, the derivative measures the rate at which a quantity changes. In other words, it tells us how a function changes as its input changes. The derivative of a function \\( f(x) \\) with respect to \\( x \\) is denoted as \\( f'(x) \\) or \\( \f",
    "rac{df}{dx} \\).\n",
    "\n",
    "For example, if \\( f(x) = x^2 \\), then its derivative is:\n",
    "\n",
    "\\[\n",
    "f'(x) = 2x\n",
    "\\]\n",
    "\n",
    "### Differentiation Rules\n",
    "\n",
    "Some basic differentiation rules you should know include:\n",
    "\n",
    "1. **Power Rule**: \n",
    "   \\[\n",
    "   \f",
    "rac{d}{dx} \\left( x^n \r",
    "ight) = n \\cdot x^{n-1}\n",
    "   \\]\n",
    "   Example: \\( \f",
    "rac{d}{dx} \\left( x^3 \r",
    "ight) = 3x^2 \\)\n",
    "\n",
    "2. **Sum Rule**: \n",
    "   \\[\n",
    "   \f",
    "rac{d}{dx} \\left( f(x) + g(x) \r",
    "ight) = f'(x) + g'(x)\n",
    "   \\]\n",
    "   Example: \\( \f",
    "rac{d}{dx} \\left( x^2 + 3x \r",
    "ight) = 2x + 3 \\)\n",
    "\n",
    "3. **Product Rule**: \n",
    "   \\[\n",
    "   \f",
    "rac{d}{dx} \\left( f(x)g(x) \r",
    "ight) = f'(x)g(x) + f(x)g'(x)\n",
    "   \\]\n",
    "   Example: \\( \f",
    "rac{d}{dx} \\left( x^2 \\cdot e^x \r",
    "ight) = 2x \\cdot e^x + x^2 \\cdot e^x \\)\n",
    "\n",
    "4. **Quotient Rule**: \n",
    "   \\[\n",
    "   \f",
    "rac{d}{dx} \\left( \f",
    "rac{f(x)}{g(x)} \r",
    "ight) = \f",
    "rac{f'(x)g(x) - f(x)g'(x)}{g(x)^2}\n",
    "   \\]\n",
    "   Example: \\( \f",
    "rac{d}{dx} \\left( \f",
    "rac{x^2}{e^x} \r",
    "ight) = \f",
    "rac{2x \\cdot e^x - x^2 \\cdot e^x}{(e^x)^2} \\)\n",
    "\n",
    "5. **Chain Rule**: \n",
    "   \\[\n",
    "   \f",
    "rac{d}{dx} \\left( f(g(x)) \r",
    "ight) = f'(g(x)) \\cdot g'(x)\n",
    "   \\]\n",
    "   Example: \\( \f",
    "rac{d}{dx} \\left( e^{x^2} \r",
    "ight) = 2x \\cdot e^{x^2} \\)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a3fd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example: Calculating derivatives using sympy\n",
    "import sympy as sp\n",
    "\n",
    "# Define the variable and function\n",
    "x = sp.Symbol('x')\n",
    "f = x**3\n",
    "\n",
    "# Calculate the derivative\n",
    "f_prime = sp.diff(f, x)\n",
    "f_prime\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a57a374",
   "metadata": {},
   "source": [
    "\n",
    "### Application in Machine Learning\n",
    "\n",
    "Derivatives are heavily used in machine learning algorithms for optimization, especially in the calculation of **gradients**. The gradient is used in optimization algorithms like **gradient descent** to minimize the loss function by updating model parameters.\n",
    "\n",
    "For example, in a neural network, the derivative of the loss function with respect to the weights (parameters) is calculated during backpropagation.\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
