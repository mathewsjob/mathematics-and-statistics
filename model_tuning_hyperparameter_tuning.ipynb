{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49451015",
   "metadata": {},
   "source": [
    "# Model Tuning for Machine Learning: Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbd20f2",
   "metadata": {},
   "source": [
    "## 1. What is Hyperparameter Tuning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85eb03e1",
   "metadata": {},
   "source": [
    "\n",
    "### What are Hyperparameters?\n",
    "\n",
    "Hyperparameters are parameters of the learning algorithm itself, rather than the model. They are set before the learning process begins and control how the model learns, such as the learning rate, the number of trees in a random forest, or the regularization strength.\n",
    "\n",
    "### Hyperparameter Tuning\n",
    "\n",
    "Hyperparameter tuning is the process of finding the optimal set of hyperparameters that result in the best performance for the model. Two common methods for hyperparameter tuning are **Grid Search** and **Random Search**.\n",
    "\n",
    "- **Grid Search**: Evaluates all possible combinations of hyperparameters within a specified range.\n",
    "- **Random Search**: Randomly samples hyperparameters from a specified range.\n",
    "\n",
    "### Example: Tuning Hyperparameters Using Grid Search\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d79955",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Example: Tuning hyperparameters using Grid Search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Performing grid search\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Best hyperparameters\n",
    "grid_search.best_params_\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a893aa39",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Random Search\n",
    "\n",
    "Random search is another method for hyperparameter tuning that randomly samples hyperparameters from a specified range. It can be more efficient than grid search, especially when the search space is large.\n",
    "\n",
    "### Example: Tuning Hyperparameters Using Random Search\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b411003",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Example: Tuning hyperparameters using Random Search\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=10, cv=5)\n",
    "random_search.fit(X, y)\n",
    "\n",
    "# Best hyperparameters\n",
    "random_search.best_params_\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d18fc78",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Cross-Validation in Hyperparameter Tuning\n",
    "\n",
    "When tuning hyperparameters, it is important to use cross-validation to ensure that the model is not overfitting to a specific set of hyperparameters. Cross-validation splits the data into multiple training and validation sets, helping to evaluate the generalization performance of the model.\n",
    "\n",
    "## Applications in Machine Learning\n",
    "\n",
    "- **Hyperparameter Tuning** is essential for optimizing the performance of machine learning models.\n",
    "- **Grid Search** and **Random Search** are popular methods to find the best combination of hyperparameters.\n",
    "- **Cross-Validation** ensures that the tuned model generalizes well to new data.\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
